{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, I demonstrate a couple of useful things.  \n",
    "\n",
    "I'm going to use Python because it is well-suited to this sort of stuff, but you may use whatever language with which you are most comfortable.\n",
    "1. reading data from a CSV formatted file (valdosta.adsb)\n",
    "2. reading data from a JSON formatted file (valdosta.gps)\n",
    "3. merging these two files by datetime stamp, so that observations in each close in time are matched up.\n",
    "\n",
    "About the data.  File valdosta.adsb contains summarized data of aircraft positions and altitudes. Here's what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date_time      mode flight_id  hex_id altitude       lat       lng  \\\n",
      "0          Starting       NaN       NaN     NaN      NaN       NaN       NaN   \n",
      "1   20150618-133743  Updating     XXXXX  AA2A8A    40000   0.00000   0.00000   \n",
      "2   20150618-133743  Updating     XXXXX  A60EDB    21000   0.00000   0.00000   \n",
      "3   20150618-133743  Updating     XXXXX  AD6035    13775   0.00000   0.00000   \n",
      "4   20150618-133743  Updating     XXXXX  A1AC69    13100   0.00000   0.00000   \n",
      "5   20150618-133743  Updating     XXXXX  A29EB6    30450   0.00000   0.00000   \n",
      "6   20150618-133743  Updating     XXXXX  A5E48A    36000   0.00000   0.00000   \n",
      "7   20150618-133743  Updating     XXXXX  A2172E        0   0.00000   0.00000   \n",
      "8   20150618-133743  Updating     XXXXX  AD18A3    28300   0.00000   0.00000   \n",
      "9   20150618-133743  Updating     XXXXX  A3A0EB    36000   0.00000   0.00000   \n",
      "10  20150618-133743  Updating     XXXXX  AC8CF1    36975   0.00000   0.00000   \n",
      "11  20150618-133743  Updating     XXXXX  AD4395    22725   0.00000   0.00000   \n",
      "12  20150618-133743  Updating     XXXXX  AC6FA4    12825   0.00000   0.00000   \n",
      "13  20150618-133743  Updating     XXXXX  A452C4    16250   0.00000   0.00000   \n",
      "14  20150618-133746  Updating     XXXXX  A34721    27950  34.80688 -84.91154   \n",
      "15  20150618-133746  Updating     XXXXX  A6E4E4    23525   0.00000   0.00000   \n",
      "16  20150618-133752  Updating     XXXXX  AA886B    35150   0.00000   0.00000   \n",
      "17  20150618-133752  Updating     XXXXX  AA7757    41000       NaN       NaN   \n",
      "18  20150618-133752  Updating     XXXXX  ADD66C    13750   0.00000   0.00000   \n",
      "19  20150618-133752  Updating  784       A1D4C3    36050  34.32422 -85.04091   \n",
      "\n",
      "    in_view  \n",
      "0       NaN  \n",
      "1      23.0  \n",
      "2      23.0  \n",
      "3      23.0  \n",
      "4      23.0  \n",
      "5      23.0  \n",
      "6      23.0  \n",
      "7      23.0  \n",
      "8      23.0  \n",
      "9      23.0  \n",
      "10     23.0  \n",
      "11     23.0  \n",
      "12     23.0  \n",
      "13     23.0  \n",
      "14     24.0  \n",
      "15     24.0  \n",
      "16     24.0  \n",
      "17     24.0  \n",
      "18     24.0  \n",
      "19     24.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "\n",
    "def main():\n",
    "    adsb_df = read_csv( 'valdosta1.adsb', names=['date_time', 'mode', 'flight_id', \n",
    "        'hex_id', 'altitude', 'lat', 'lng', 'in_view'])\n",
    "    print(adsb_df.head(20))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got the idea for how to do this from here:\n",
    "https://stackoverflow.com/questions/15006298/how-to-preview-a-part-of-a-large-pandas-dataframe-in-ipython-notebook\n",
    "Clearly the data still need some filtering but we're on the right track and pandas is doing a lot of the heavy lifting for us.\n",
    "\n",
    "The json formatted file contains GPS position data for my aircraft receiver, which was located in a moving car.\n",
    "\n",
    "Let's look at reading data from the corresponding json-formatted file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   activated    alt     bps    class  climb  cycle  \\\n",
      "0                        NaN    NaN     NaN  VERSION    NaN    NaN   \n",
      "1                        NaN    NaN     NaN  DEVICES    NaN    NaN   \n",
      "2                        NaN    NaN     NaN    WATCH    NaN    NaN   \n",
      "3   2015-06-18T03:08:59.900Z    NaN  9600.0   DEVICE    NaN    1.0   \n",
      "4                        NaN  227.0     NaN      TPV    NaN    NaN   \n",
      "5                        NaN  227.0     NaN      TPV    NaN    NaN   \n",
      "6                        NaN    NaN     NaN      SKY    NaN    NaN   \n",
      "7                        NaN  227.0     NaN      TPV    NaN    NaN   \n",
      "8                        NaN  227.0     NaN      TPV    0.0    NaN   \n",
      "9   2015-06-18T03:09:01.205Z    NaN  9600.0   DEVICE    NaN    1.0   \n",
      "10  2015-06-18T03:09:01.926Z    NaN  9600.0   DEVICE    NaN    1.0   \n",
      "11                       NaN  227.0     NaN      TPV    0.0    NaN   \n",
      "12                       NaN  227.0     NaN      TPV    0.0    NaN   \n",
      "13                       NaN  227.0     NaN      TPV    0.0    NaN   \n",
      "14                       NaN    NaN     NaN      SKY    NaN    NaN   \n",
      "15                       NaN  227.0     NaN      TPV    0.0    NaN   \n",
      "16                       NaN  227.0     NaN      TPV    0.0    NaN   \n",
      "17                       NaN  227.0     NaN      TPV    0.0    NaN   \n",
      "18                       NaN  226.9     NaN      TPV   -0.1    NaN   \n",
      "19                       NaN  226.9     NaN      TPV    0.0    NaN   \n",
      "20                       NaN    NaN     NaN      SKY    NaN    NaN   \n",
      "21                       NaN  226.9     NaN      TPV    0.0    NaN   \n",
      "22                       NaN  226.9     NaN      TPV    0.0    NaN   \n",
      "23                       NaN  226.9     NaN      TPV    0.0    NaN   \n",
      "24                       NaN  226.9     NaN      TPV    0.0    NaN   \n",
      "25                       NaN  226.9     NaN      TPV    0.0    NaN   \n",
      "26                       NaN    NaN     NaN      SKY    NaN    NaN   \n",
      "27                       NaN  226.9     NaN      TPV    0.0    NaN   \n",
      "28                       NaN  226.9     NaN      TPV    0.0    NaN   \n",
      "29                       NaN  226.9     NaN      TPV    0.0    NaN   \n",
      "30                       NaN  226.9     NaN      TPV    0.0    NaN   \n",
      "31                       NaN  226.9     NaN      TPV    0.0    NaN   \n",
      "32                       NaN    NaN     NaN      SKY    NaN    NaN   \n",
      "33                       NaN  226.9     NaN      TPV    0.0    NaN   \n",
      "34                       NaN  226.9     NaN      TPV    0.0    NaN   \n",
      "35                       NaN  226.9     NaN      TPV    0.0    NaN   \n",
      "36                       NaN  226.9     NaN      TPV    0.0    NaN   \n",
      "37                       NaN  226.9     NaN      TPV    0.0    NaN   \n",
      "38                       NaN    NaN     NaN      SKY    NaN    NaN   \n",
      "39                       NaN  226.9     NaN      TPV    0.0    NaN   \n",
      "40                       NaN  226.9     NaN      TPV    0.0    NaN   \n",
      "41                       NaN  226.9     NaN      TPV    0.0    NaN   \n",
      "42                       NaN  226.9     NaN      TPV    0.0    NaN   \n",
      "43                       NaN  226.9     NaN      TPV    0.0    NaN   \n",
      "44                       NaN    NaN     NaN      SKY    NaN    NaN   \n",
      "45                       NaN  226.9     NaN      TPV    0.0    NaN   \n",
      "46                       NaN  226.9     NaN      TPV    0.0    NaN   \n",
      "47                       NaN  226.9     NaN      TPV    0.0    NaN   \n",
      "48                       NaN  226.9     NaN      TPV    0.0    NaN   \n",
      "49                       NaN  226.9     NaN      TPV    0.0    NaN   \n",
      "\n",
      "          device                                            devices  \\\n",
      "0            NaN                                                NaN   \n",
      "1            NaN  [{'class': 'DEVICE', 'path': '/dev/ttyUSB0', '...   \n",
      "2            NaN                                                NaN   \n",
      "3            NaN                                                NaN   \n",
      "4   /dev/ttyUSB0                                                NaN   \n",
      "5   /dev/ttyUSB0                                                NaN   \n",
      "6   /dev/ttyUSB0                                                NaN   \n",
      "7   /dev/ttyUSB0                                                NaN   \n",
      "8   /dev/ttyUSB0                                                NaN   \n",
      "9            NaN                                                NaN   \n",
      "10           NaN                                                NaN   \n",
      "11  /dev/ttyUSB0                                                NaN   \n",
      "12  /dev/ttyUSB0                                                NaN   \n",
      "13  /dev/ttyUSB0                                                NaN   \n",
      "14  /dev/ttyUSB0                                                NaN   \n",
      "15  /dev/ttyUSB0                                                NaN   \n",
      "16  /dev/ttyUSB0                                                NaN   \n",
      "17  /dev/ttyUSB0                                                NaN   \n",
      "18  /dev/ttyUSB0                                                NaN   \n",
      "19  /dev/ttyUSB0                                                NaN   \n",
      "20  /dev/ttyUSB0                                                NaN   \n",
      "21  /dev/ttyUSB0                                                NaN   \n",
      "22  /dev/ttyUSB0                                                NaN   \n",
      "23  /dev/ttyUSB0                                                NaN   \n",
      "24  /dev/ttyUSB0                                                NaN   \n",
      "25  /dev/ttyUSB0                                                NaN   \n",
      "26  /dev/ttyUSB0                                                NaN   \n",
      "27  /dev/ttyUSB0                                                NaN   \n",
      "28  /dev/ttyUSB0                                                NaN   \n",
      "29  /dev/ttyUSB0                                                NaN   \n",
      "30  /dev/ttyUSB0                                                NaN   \n",
      "31  /dev/ttyUSB0                                                NaN   \n",
      "32  /dev/ttyUSB0                                                NaN   \n",
      "33  /dev/ttyUSB0                                                NaN   \n",
      "34  /dev/ttyUSB0                                                NaN   \n",
      "35  /dev/ttyUSB0                                                NaN   \n",
      "36  /dev/ttyUSB0                                                NaN   \n",
      "37  /dev/ttyUSB0                                                NaN   \n",
      "38  /dev/ttyUSB0                                                NaN   \n",
      "39  /dev/ttyUSB0                                                NaN   \n",
      "40  /dev/ttyUSB0                                                NaN   \n",
      "41  /dev/ttyUSB0                                                NaN   \n",
      "42  /dev/ttyUSB0                                                NaN   \n",
      "43  /dev/ttyUSB0                                                NaN   \n",
      "44  /dev/ttyUSB0                                                NaN   \n",
      "45  /dev/ttyUSB0                                                NaN   \n",
      "46  /dev/ttyUSB0                                                NaN   \n",
      "47  /dev/ttyUSB0                                                NaN   \n",
      "48  /dev/ttyUSB0                                                NaN   \n",
      "49  /dev/ttyUSB0                                                NaN   \n",
      "\n",
      "          driver  enable  ...  speed  stopbits  tag  tdop  \\\n",
      "0            NaN     NaN  ...    NaN       NaN  NaN   NaN   \n",
      "1            NaN     NaN  ...    NaN       NaN  NaN   NaN   \n",
      "2            NaN     1.0  ...    NaN       NaN  NaN   NaN   \n",
      "3   Generic NMEA     NaN  ...    NaN       1.0  NaN   NaN   \n",
      "4            NaN     NaN  ...    NaN       NaN  GGA   NaN   \n",
      "5            NaN     NaN  ...    NaN       NaN  GSA   NaN   \n",
      "6            NaN     NaN  ...    NaN       NaN  GSV  3.48   \n",
      "7            NaN     NaN  ...  0.010       NaN  RMC   NaN   \n",
      "8            NaN     NaN  ...  0.010       NaN  RMC   NaN   \n",
      "9       MTK-3301     NaN  ...    NaN       1.0  NaN   NaN   \n",
      "10  Generic NMEA     NaN  ...    NaN       1.0  NaN   NaN   \n",
      "11           NaN     NaN  ...  0.010       NaN  RMC   NaN   \n",
      "12           NaN     NaN  ...  0.010       NaN  RMC   NaN   \n",
      "13           NaN     NaN  ...  0.005       NaN  RMC   NaN   \n",
      "14           NaN     NaN  ...    NaN       NaN  GSV  3.48   \n",
      "15           NaN     NaN  ...  0.005       NaN  RMC   NaN   \n",
      "16           NaN     NaN  ...  0.010       NaN  RMC   NaN   \n",
      "17           NaN     NaN  ...  0.010       NaN  RMC   NaN   \n",
      "18           NaN     NaN  ...  0.010       NaN  RMC   NaN   \n",
      "19           NaN     NaN  ...  0.010       NaN  RMC   NaN   \n",
      "20           NaN     NaN  ...    NaN       NaN  GSV  3.48   \n",
      "21           NaN     NaN  ...  0.005       NaN  RMC   NaN   \n",
      "22           NaN     NaN  ...  0.010       NaN  RMC   NaN   \n",
      "23           NaN     NaN  ...  0.015       NaN  RMC   NaN   \n",
      "24           NaN     NaN  ...  0.015       NaN  RMC   NaN   \n",
      "25           NaN     NaN  ...  0.015       NaN  RMC   NaN   \n",
      "26           NaN     NaN  ...    NaN       NaN  GSV  3.42   \n",
      "27           NaN     NaN  ...  0.010       NaN  RMC   NaN   \n",
      "28           NaN     NaN  ...  0.010       NaN  RMC   NaN   \n",
      "29           NaN     NaN  ...  0.010       NaN  RMC   NaN   \n",
      "30           NaN     NaN  ...  0.010       NaN  RMC   NaN   \n",
      "31           NaN     NaN  ...  0.010       NaN  RMC   NaN   \n",
      "32           NaN     NaN  ...    NaN       NaN  GSV  3.43   \n",
      "33           NaN     NaN  ...  0.010       NaN  RMC   NaN   \n",
      "34           NaN     NaN  ...  0.010       NaN  RMC   NaN   \n",
      "35           NaN     NaN  ...  0.010       NaN  RMC   NaN   \n",
      "36           NaN     NaN  ...  0.010       NaN  RMC   NaN   \n",
      "37           NaN     NaN  ...  0.010       NaN  RMC   NaN   \n",
      "38           NaN     NaN  ...    NaN       NaN  GSV  3.43   \n",
      "39           NaN     NaN  ...  0.010       NaN  RMC   NaN   \n",
      "40           NaN     NaN  ...  0.010       NaN  RMC   NaN   \n",
      "41           NaN     NaN  ...  0.010       NaN  RMC   NaN   \n",
      "42           NaN     NaN  ...  0.010       NaN  RMC   NaN   \n",
      "43           NaN     NaN  ...  0.010       NaN  RMC   NaN   \n",
      "44           NaN     NaN  ...    NaN       NaN  GSV  3.43   \n",
      "45           NaN     NaN  ...  0.010       NaN  RMC   NaN   \n",
      "46           NaN     NaN  ...  0.005       NaN  RMC   NaN   \n",
      "47           NaN     NaN  ...  0.005       NaN  RMC   NaN   \n",
      "48           NaN     NaN  ...  0.005       NaN  RMC   NaN   \n",
      "49           NaN     NaN  ...  0.005       NaN  RMC   NaN   \n",
      "\n",
      "                        time  timing   track  vdop  xdop  ydop  \n",
      "0                        NaN     NaN     NaN   NaN   NaN   NaN  \n",
      "1                        NaN     NaN     NaN   NaN   NaN   NaN  \n",
      "2                        NaN     0.0     NaN   NaN   NaN   NaN  \n",
      "3                        NaN     NaN     NaN   NaN   NaN   NaN  \n",
      "4                        NaN     NaN     NaN   NaN   NaN   NaN  \n",
      "5                        NaN     NaN     NaN   NaN   NaN   NaN  \n",
      "6                        NaN     NaN     NaN  4.45  1.34  1.09  \n",
      "7   2015-06-18T13:34:55.000Z     NaN  141.12   NaN   NaN   NaN  \n",
      "8   2015-06-18T13:34:56.000Z     NaN  140.06   NaN   NaN   NaN  \n",
      "9                        NaN     NaN     NaN   NaN   NaN   NaN  \n",
      "10                       NaN     NaN     NaN   NaN   NaN   NaN  \n",
      "11  2015-06-18T13:34:57.000Z     NaN  136.46   NaN   NaN   NaN  \n",
      "12  2015-06-18T13:34:58.000Z     NaN  134.16   NaN   NaN   NaN  \n",
      "13  2015-06-18T13:34:59.000Z     NaN  244.59   NaN   NaN   NaN  \n",
      "14                       NaN     NaN     NaN  4.45  1.34  1.09  \n",
      "15  2015-06-18T13:35:00.000Z     NaN  288.26   NaN   NaN   NaN  \n",
      "16  2015-06-18T13:35:01.000Z     NaN  318.41   NaN   NaN   NaN  \n",
      "17  2015-06-18T13:35:02.000Z     NaN  332.62   NaN   NaN   NaN  \n",
      "18  2015-06-18T13:35:03.000Z     NaN  326.85   NaN   NaN   NaN  \n",
      "19  2015-06-18T13:35:04.000Z     NaN  330.28   NaN   NaN   NaN  \n",
      "20                       NaN     NaN     NaN  4.44  1.34  1.09  \n",
      "21  2015-06-18T13:35:05.000Z     NaN   39.10   NaN   NaN   NaN  \n",
      "22  2015-06-18T13:35:06.000Z     NaN  114.21   NaN   NaN   NaN  \n",
      "23  2015-06-18T13:35:07.000Z     NaN  155.59   NaN   NaN   NaN  \n",
      "24  2015-06-18T13:35:08.000Z     NaN  165.93   NaN   NaN   NaN  \n",
      "25  2015-06-18T13:35:09.000Z     NaN  160.26   NaN   NaN   NaN  \n",
      "26                       NaN     NaN     NaN  4.38  1.32  1.07  \n",
      "27  2015-06-18T13:35:10.000Z     NaN  160.57   NaN   NaN   NaN  \n",
      "28  2015-06-18T13:35:11.000Z     NaN  218.40   NaN   NaN   NaN  \n",
      "29  2015-06-18T13:35:12.000Z     NaN  237.21   NaN   NaN   NaN  \n",
      "30  2015-06-18T13:35:13.000Z     NaN   14.18   NaN   NaN   NaN  \n",
      "31  2015-06-18T13:35:14.000Z     NaN    3.28   NaN   NaN   NaN  \n",
      "32                       NaN     NaN     NaN  4.39  1.33  1.08  \n",
      "33  2015-06-18T13:35:15.000Z     NaN  345.35   NaN   NaN   NaN  \n",
      "34  2015-06-18T13:35:16.000Z     NaN  355.05   NaN   NaN   NaN  \n",
      "35  2015-06-18T13:35:17.000Z     NaN   45.19   NaN   NaN   NaN  \n",
      "36  2015-06-18T13:35:18.000Z     NaN   79.22   NaN   NaN   NaN  \n",
      "37  2015-06-18T13:35:19.000Z     NaN  148.91   NaN   NaN   NaN  \n",
      "38                       NaN     NaN     NaN  4.39  1.33  1.08  \n",
      "39  2015-06-18T13:35:20.000Z     NaN  164.72   NaN   NaN   NaN  \n",
      "40  2015-06-18T13:35:21.000Z     NaN  174.63   NaN   NaN   NaN  \n",
      "41  2015-06-18T13:35:22.000Z     NaN  174.97   NaN   NaN   NaN  \n",
      "42  2015-06-18T13:35:23.000Z     NaN  210.11   NaN   NaN   NaN  \n",
      "43  2015-06-18T13:35:24.000Z     NaN  266.04   NaN   NaN   NaN  \n",
      "44                       NaN     NaN     NaN  4.39  1.33  1.08  \n",
      "45  2015-06-18T13:35:25.000Z     NaN  331.71   NaN   NaN   NaN  \n",
      "46  2015-06-18T13:35:26.000Z     NaN  359.49   NaN   NaN   NaN  \n",
      "47  2015-06-18T13:35:27.000Z     NaN   33.55   NaN   NaN   NaN  \n",
      "48  2015-06-18T13:35:28.000Z     NaN   51.44   NaN   NaN   NaN  \n",
      "49  2015-06-18T13:35:29.000Z     NaN   31.93   NaN   NaN   NaN  \n",
      "\n",
      "[50 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_json\n",
    "\n",
    "def main():\n",
    "    gps_df = read_json( 'valdosta1.gps', lines=True)\n",
    "    print(gps_df.head(50))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got this idea from: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_json.html\n",
    "Not all the data is shown in this abbreviated (and messy) preview.  Specifically, the latitude and longitude, two attributes of great interest here, are lost in the ellipsis (...).  Don't worry, we'll filter this data frame down in a subsequent step.\n",
    "\n",
    "Let's go back to the CSV file and filter for just the rows we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date_time      mode flight_id  hex_id altitude       lat       lng  \\\n",
      "14   20150618-133746  Updating     XXXXX  A34721    27950  34.80688 -84.91154   \n",
      "19   20150618-133752  Updating  784       A1D4C3    36050  34.32422 -85.04091   \n",
      "32   20150618-133847  Updating     XXXXX  A34721    26500  34.95886 -85.11237   \n",
      "37   20150618-133847  Updating     XXXXX  A399D4    27325  35.02758 -85.26049   \n",
      "41   20150618-133853  Updating     XXXXX  AA7757    41000  33.78484 -83.94429   \n",
      "43   20150618-133853  Updating  784       A1D4C3    36700  34.43559 -85.13917   \n",
      "47   20150618-133912  Updating  UAL1096   AA7E2E    36000  34.83902 -84.98340   \n",
      "51   20150618-133930  Updating     XXXXX  AB5F00    37000  34.14088 -85.70468   \n",
      "60   20150618-133952  Updating     XXXXX  A34721    25925  34.99672 -85.16281   \n",
      "65   20150618-133952  Updating     XXXXX  A399D4    27325  35.02758 -85.26049   \n",
      "70   20150618-133955  Updating     XXXXX  AA7757    41000  33.78484 -83.94429   \n",
      "72   20150618-133955  Updating  784       A1D4C3    37050  34.52174 -85.21557   \n",
      "80   20150618-134016  Updating  UAL1096   AA7E2E    36000  34.78430 -85.07532   \n",
      "84   20150618-134035  Updating     XXXXX  AB5F00    37000  34.14088 -85.70468   \n",
      "94   20150618-134058  Updating     XXXXX  AA7757    41000  33.94012 -83.69951   \n",
      "95   20150618-134058  Updating     XXXXX  A34721    25925  34.99672 -85.16281   \n",
      "101  20150618-134058  Updating     XXXXX  A399D4    27325  35.02758 -85.26049   \n",
      "103  20150618-134058  Updating  784       A1D4C3    37050  34.60707 -85.29129   \n",
      "112  20150618-134117  Updating  UAL1096   AA7E2E    36000  34.73882 -85.15183   \n",
      "129  20150618-134203  Updating     XXXXX  AA7757    41000  33.94012 -83.69951   \n",
      "\n",
      "     in_view  \n",
      "14      24.0  \n",
      "19      24.0  \n",
      "32      28.0  \n",
      "37      28.0  \n",
      "41      28.0  \n",
      "43      28.0  \n",
      "47      31.0  \n",
      "51      31.0  \n",
      "60      33.0  \n",
      "65      33.0  \n",
      "70      32.0  \n",
      "72      32.0  \n",
      "80      32.0  \n",
      "84      33.0  \n",
      "94      34.0  \n",
      "95      34.0  \n",
      "101     34.0  \n",
      "103     34.0  \n",
      "112     35.0  \n",
      "129     35.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Read the entire file\n",
    "    adsb_df = read_csv( 'valdosta1.adsb', names=['date_time', 'mode', 'flight_id', \n",
    "        'hex_id', 'altitude', 'lat', 'lng', 'in_view'])\n",
    "\n",
    "    # first subsetting expression -- only want updates, non-zero lat/long\n",
    "    adsb_clean = adsb_df.loc[(adsb_df['mode'] == 'Updating') & (adsb_df['lat'] != 0 ) \n",
    "        & (adsb_df['lat'].notnull())]\n",
    "        \n",
    "    print(adsb_clean.head(20))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My code is based on this: https://cmdlinetips.com/2018/02/how-to-subset-pandas-dataframe-based-on-values-of-a-column/\n",
    "and: https://stackoverflow.com/questions/17071871/how-to-select-rows-from-a-dataframe-based-on-column-values\n",
    "\n",
    "Now let's clean the json data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        time      lat       lon  speed    alt   track  climb\n",
      "8   2015-06-18T13:34:56.000Z  34.3793 -84.90703  0.010  227.0  140.06    0.0\n",
      "11  2015-06-18T13:34:57.000Z  34.3793 -84.90703  0.010  227.0  136.46    0.0\n",
      "12  2015-06-18T13:34:58.000Z  34.3793 -84.90703  0.010  227.0  134.16    0.0\n",
      "13  2015-06-18T13:34:59.000Z  34.3793 -84.90703  0.005  227.0  244.59    0.0\n",
      "15  2015-06-18T13:35:00.000Z  34.3793 -84.90703  0.005  227.0  288.26    0.0\n",
      "16  2015-06-18T13:35:01.000Z  34.3793 -84.90703  0.010  227.0  318.41    0.0\n",
      "17  2015-06-18T13:35:02.000Z  34.3793 -84.90703  0.010  227.0  332.62    0.0\n",
      "18  2015-06-18T13:35:03.000Z  34.3793 -84.90703  0.010  226.9  326.85   -0.1\n",
      "19  2015-06-18T13:35:04.000Z  34.3793 -84.90703  0.010  226.9  330.28    0.0\n",
      "21  2015-06-18T13:35:05.000Z  34.3793 -84.90703  0.005  226.9   39.10    0.0\n",
      "22  2015-06-18T13:35:06.000Z  34.3793 -84.90703  0.010  226.9  114.21    0.0\n",
      "23  2015-06-18T13:35:07.000Z  34.3793 -84.90703  0.015  226.9  155.59    0.0\n",
      "24  2015-06-18T13:35:08.000Z  34.3793 -84.90703  0.015  226.9  165.93    0.0\n",
      "25  2015-06-18T13:35:09.000Z  34.3793 -84.90703  0.015  226.9  160.26    0.0\n",
      "27  2015-06-18T13:35:10.000Z  34.3793 -84.90703  0.010  226.9  160.57    0.0\n",
      "28  2015-06-18T13:35:11.000Z  34.3793 -84.90703  0.010  226.9  218.40    0.0\n",
      "29  2015-06-18T13:35:12.000Z  34.3793 -84.90703  0.010  226.9  237.21    0.0\n",
      "30  2015-06-18T13:35:13.000Z  34.3793 -84.90703  0.010  226.9   14.18    0.0\n",
      "31  2015-06-18T13:35:14.000Z  34.3793 -84.90703  0.010  226.9    3.28    0.0\n",
      "33  2015-06-18T13:35:15.000Z  34.3793 -84.90703  0.010  226.9  345.35    0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_json\n",
    "\n",
    "def main():\n",
    "    gps_df = read_json( 'valdosta1.gps', lines=True)\n",
    "\n",
    "    # GPS data stream is very rich - a lot of redundant info, including \n",
    "    # info on the satellites themselves.  We only want position (fix) related\n",
    "    # stuff.  TPV is Time, Position, Velocity\n",
    "    gps_clean = gps_df.loc[gps_df['class'] == 'TPV']\n",
    "\n",
    "    # Now keep only columns/fields we want\n",
    "    gps_clean = gps_clean.filter( items=['time', 'lat', 'lon', 'speed', 'alt', 'track', 'climb'])\n",
    "\n",
    "    # Deal with missing times\n",
    "    gps_clean = gps_clean.loc[(gps_clean['time'].notnull()) & gps_clean['climb'].notnull()]\n",
    "    print(gps_clean.head(20))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's use Pandas to merge these files by timestamp.  The first step is to convert the string times into real Datetime type, starting with the plane data (from csv):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from datetime import datetime\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Read the entire file\n",
    "    adsb_df = read_csv( 'valdosta1.adsb', names=['date_time', 'mode', 'flight_id', \n",
    "        'hex_id', 'altitude', 'lat', 'lng', 'in_view'])\n",
    "\n",
    "    # first subsetting expression -- only want updates, non-zero lat/long\n",
    "    adsb_clean = adsb_df.loc[(adsb_df['mode'] == 'Updating') & (adsb_df['lat'] != 0 ) \n",
    "        & (adsb_df['lat'].notnull())]\n",
    "\n",
    "    # Convert string date to datetime internal format, add to dataframe as dt_tm\n",
    "    # Ref: https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior\n",
    "    # and: https://stackoverflow.com/questions/18942506/add-new-column-in-pandas-dataframe-python\n",
    "\n",
    "    # kludge to turn off the dreaded SettingWithCopyWarning.  Discussion is  in SO link above.\n",
    "    pd.options.mode.chained_assignment = None\n",
    "    \n",
    "    # Compute a new column with a datetime format from the string date time column\n",
    "    adsb_clean['dt_tm'] = adsb_clean['date_time'].map( lambda x: datetime.strptime(x, '%Y%m%d-%H%M%S'))\n",
    "    \n",
    "    print(adsb_clean.head(20))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the GPS data from the json file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        time      lat       lon  speed    alt   track  climb  \\\n",
      "8   2015-06-18T13:34:56.000Z  34.3793 -84.90703  0.010  227.0  140.06    0.0   \n",
      "11  2015-06-18T13:34:57.000Z  34.3793 -84.90703  0.010  227.0  136.46    0.0   \n",
      "12  2015-06-18T13:34:58.000Z  34.3793 -84.90703  0.010  227.0  134.16    0.0   \n",
      "13  2015-06-18T13:34:59.000Z  34.3793 -84.90703  0.005  227.0  244.59    0.0   \n",
      "15  2015-06-18T13:35:00.000Z  34.3793 -84.90703  0.005  227.0  288.26    0.0   \n",
      "16  2015-06-18T13:35:01.000Z  34.3793 -84.90703  0.010  227.0  318.41    0.0   \n",
      "17  2015-06-18T13:35:02.000Z  34.3793 -84.90703  0.010  227.0  332.62    0.0   \n",
      "18  2015-06-18T13:35:03.000Z  34.3793 -84.90703  0.010  226.9  326.85   -0.1   \n",
      "19  2015-06-18T13:35:04.000Z  34.3793 -84.90703  0.010  226.9  330.28    0.0   \n",
      "21  2015-06-18T13:35:05.000Z  34.3793 -84.90703  0.005  226.9   39.10    0.0   \n",
      "22  2015-06-18T13:35:06.000Z  34.3793 -84.90703  0.010  226.9  114.21    0.0   \n",
      "23  2015-06-18T13:35:07.000Z  34.3793 -84.90703  0.015  226.9  155.59    0.0   \n",
      "24  2015-06-18T13:35:08.000Z  34.3793 -84.90703  0.015  226.9  165.93    0.0   \n",
      "25  2015-06-18T13:35:09.000Z  34.3793 -84.90703  0.015  226.9  160.26    0.0   \n",
      "27  2015-06-18T13:35:10.000Z  34.3793 -84.90703  0.010  226.9  160.57    0.0   \n",
      "28  2015-06-18T13:35:11.000Z  34.3793 -84.90703  0.010  226.9  218.40    0.0   \n",
      "29  2015-06-18T13:35:12.000Z  34.3793 -84.90703  0.010  226.9  237.21    0.0   \n",
      "30  2015-06-18T13:35:13.000Z  34.3793 -84.90703  0.010  226.9   14.18    0.0   \n",
      "31  2015-06-18T13:35:14.000Z  34.3793 -84.90703  0.010  226.9    3.28    0.0   \n",
      "33  2015-06-18T13:35:15.000Z  34.3793 -84.90703  0.010  226.9  345.35    0.0   \n",
      "\n",
      "                 dt_tm  \n",
      "8  2015-06-18 13:34:56  \n",
      "11 2015-06-18 13:34:57  \n",
      "12 2015-06-18 13:34:58  \n",
      "13 2015-06-18 13:34:59  \n",
      "15 2015-06-18 13:35:00  \n",
      "16 2015-06-18 13:35:01  \n",
      "17 2015-06-18 13:35:02  \n",
      "18 2015-06-18 13:35:03  \n",
      "19 2015-06-18 13:35:04  \n",
      "21 2015-06-18 13:35:05  \n",
      "22 2015-06-18 13:35:06  \n",
      "23 2015-06-18 13:35:07  \n",
      "24 2015-06-18 13:35:08  \n",
      "25 2015-06-18 13:35:09  \n",
      "27 2015-06-18 13:35:10  \n",
      "28 2015-06-18 13:35:11  \n",
      "29 2015-06-18 13:35:12  \n",
      "30 2015-06-18 13:35:13  \n",
      "31 2015-06-18 13:35:14  \n",
      "33 2015-06-18 13:35:15  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_json\n",
    "from datetime import datetime\n",
    "\n",
    "def main():\n",
    "    gps_df = read_json( 'valdosta1.gps', lines=True)\n",
    "\n",
    "    # GPS data stream is very rich - a lot of redundant info, including \n",
    "    # info on the satellites themselves.  We only want position (fix) related\n",
    "    # stuff.  TPV is Time, Position, Velocity\n",
    "    gps_clean = gps_df.loc[gps_df['class'] == 'TPV']\n",
    "\n",
    "    # Now keep only columns/fields we want\n",
    "    gps_clean = gps_clean.filter( items=['time', 'lat', 'lon', 'speed', 'alt', 'track', 'climb'])\n",
    "\n",
    "    # Deal with missing times\n",
    "    gps_clean = gps_clean.loc[(gps_clean['time'].notnull()) & gps_clean['climb'].notnull()]\n",
    "\n",
    "    # Convert string date to datetime internal format, add to dataframe as dt_tm\n",
    "    # Ref: https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior\n",
    "    # and: https://stackoverflow.com/questions/18942506/add-new-column-in-pandas-dataframe-python\n",
    "\n",
    "    # kludge to turn off the dreaded SettingWithCopyWarning.  Discussion is  in SO link above.\n",
    "    pd.options.mode.chained_assignment = None\n",
    "\n",
    "    # Compute a new column with a datetime format from the string date time column\n",
    "    # string dates and times look like this 2015-06-18T13:43:40.000Z\n",
    "    gps_clean['dt_tm'] = gps_clean['time'].map( lambda x: datetime.strptime(x, '%Y-%m-%dT%H:%M:%S.000Z'))\n",
    "    print(gps_clean.head(20))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's merge using Pandas.  For simple merges, you could probably just round to the nearest minute and work that way, but I wanted to try the more elegant Pandas method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected rows\n",
      "    hex_id        date_time  lat_plane  lng_plane                      time  \\\n",
      "0   A34721  20150618-133746   34.80688  -84.91154  2015-06-18T13:37:46.000Z   \n",
      "1   A1D4C3  20150618-133752   34.32422  -85.04091  2015-06-18T13:37:52.000Z   \n",
      "2   A34721  20150618-133847   34.95886  -85.11237  2015-06-18T13:38:47.000Z   \n",
      "3   A399D4  20150618-133847   35.02758  -85.26049  2015-06-18T13:38:47.000Z   \n",
      "4   AA7757  20150618-133853   33.78484  -83.94429  2015-06-18T13:38:53.000Z   \n",
      "5   A1D4C3  20150618-133853   34.43559  -85.13917  2015-06-18T13:38:53.000Z   \n",
      "6   AA7E2E  20150618-133912   34.83902  -84.98340  2015-06-18T13:39:12.000Z   \n",
      "7   AB5F00  20150618-133930   34.14088  -85.70468  2015-06-18T13:39:30.000Z   \n",
      "8   A34721  20150618-133952   34.99672  -85.16281  2015-06-18T13:39:52.000Z   \n",
      "9   A399D4  20150618-133952   35.02758  -85.26049  2015-06-18T13:39:52.000Z   \n",
      "10  AA7757  20150618-133955   33.78484  -83.94429  2015-06-18T13:39:55.000Z   \n",
      "11  A1D4C3  20150618-133955   34.52174  -85.21557  2015-06-18T13:39:55.000Z   \n",
      "12  AA7E2E  20150618-134016   34.78430  -85.07532  2015-06-18T13:40:16.000Z   \n",
      "13  AB5F00  20150618-134035   34.14088  -85.70468  2015-06-18T13:40:35.000Z   \n",
      "14  AA7757  20150618-134058   33.94012  -83.69951  2015-06-18T13:40:58.000Z   \n",
      "15  A34721  20150618-134058   34.99672  -85.16281  2015-06-18T13:40:58.000Z   \n",
      "16  A399D4  20150618-134058   35.02758  -85.26049  2015-06-18T13:40:58.000Z   \n",
      "17  A1D4C3  20150618-134058   34.60707  -85.29129  2015-06-18T13:40:58.000Z   \n",
      "18  AA7E2E  20150618-134117   34.73882  -85.15183  2015-06-18T13:41:17.000Z   \n",
      "19  AA7757  20150618-134203   33.94012  -83.69951  2015-06-18T13:42:03.000Z   \n",
      "20  A399D4  20150618-134203   35.02758  -85.26049  2015-06-18T13:42:03.000Z   \n",
      "21  A1D4C3  20150618-134203   34.74929  -85.41801  2015-06-18T13:42:03.000Z   \n",
      "22  AA7E2E  20150618-134220   34.61620  -85.35713  2015-06-18T13:42:20.000Z   \n",
      "23  AA7757  20150618-134305   33.94012  -83.69951  2015-06-18T13:43:05.000Z   \n",
      "24  A399D4  20150618-134305   35.02758  -85.26049  2015-06-18T13:43:05.000Z   \n",
      "25  A1D4C3  20150618-134305   34.84682  -85.50522  2015-06-18T13:43:05.000Z   \n",
      "26  AA7E2E  20150618-134326   34.61620  -85.35713  2015-06-18T13:43:26.000Z   \n",
      "27  A1D4C3  20150618-134409   34.92814  -85.57817  2015-06-18T13:44:09.000Z   \n",
      "28  AA7E2E  20150618-134439   34.61620  -85.35713  2015-06-18T13:44:39.000Z   \n",
      "29  A1D4C3  20150618-134513   34.92814  -85.57817  2015-06-18T13:45:13.000Z   \n",
      "30  AA7E2E  20150618-134541   34.61620  -85.35713  2015-06-18T13:45:41.000Z   \n",
      "31  A1D4C3  20150618-134620   34.92814  -85.57817  2015-06-18T13:46:20.000Z   \n",
      "32  AA7E2E  20150618-134706   34.61620  -85.35713  2015-06-18T13:47:06.000Z   \n",
      "33  AA7052  20150618-135016   33.99486  -84.90337  2015-06-18T13:50:16.000Z   \n",
      "34  71BE11  20150618-135136   34.28874  -85.23036  2015-06-18T13:51:36.000Z   \n",
      "35  503DA2  20150618-135136   34.01418  -84.34633  2015-06-18T13:51:36.000Z   \n",
      "36  AA7052  20150618-135136   33.96304  -84.86255  2015-06-18T13:51:36.000Z   \n",
      "37  71BE11  20150618-135246   34.28874  -85.23036  2015-06-18T13:52:46.000Z   \n",
      "38  503DA2  20150618-135246   34.09211  -84.32814  2015-06-18T13:52:46.000Z   \n",
      "39  AA7052  20150618-135246   33.96304  -84.86255  2015-06-18T13:52:46.000Z   \n",
      "40  503DA2  20150618-135433   34.24555  -84.29209  2015-06-18T13:54:33.000Z   \n",
      "41  AA7052  20150618-135433   33.96304  -84.86255  2015-06-18T13:54:33.000Z   \n",
      "42  71BE11  20150618-135549   34.06772  -84.99716  2015-06-18T13:55:49.000Z   \n",
      "43  503DA2  20150618-135549   34.33586  -84.27097  2015-06-18T13:55:49.000Z   \n",
      "44  A53436  20150618-135623   34.73421  -84.81903  2015-06-18T13:56:23.000Z   \n",
      "45  71BE11  20150618-135659   34.06772  -84.99716  2015-06-18T13:56:59.000Z   \n",
      "46  503DA2  20150618-135659   34.33586  -84.27097  2015-06-18T13:56:59.000Z   \n",
      "47  A53436  20150618-135741   34.73421  -84.81903  2015-06-18T13:57:41.000Z   \n",
      "48  71BE11  20150618-135812   33.82283  -84.75874  2015-06-18T13:58:12.000Z   \n",
      "49  A53436  20150618-135851   34.29499  -84.66534  2015-06-18T13:58:51.000Z   \n",
      "\n",
      "          lat        lon  \n",
      "0   34.379300 -84.907030  \n",
      "1   34.379302 -84.907030  \n",
      "2   34.378902 -84.907785  \n",
      "3   34.378902 -84.907785  \n",
      "4   34.378882 -84.907828  \n",
      "5   34.378882 -84.907828  \n",
      "6   34.378632 -84.907885  \n",
      "7   34.378015 -84.908357  \n",
      "8   34.377765 -84.909217  \n",
      "9   34.377765 -84.909217  \n",
      "10  34.377750 -84.909275  \n",
      "11  34.377750 -84.909275  \n",
      "12  34.377735 -84.909338  \n",
      "13  34.377650 -84.909635  \n",
      "14  34.377182 -84.911395  \n",
      "15  34.377182 -84.911395  \n",
      "16  34.377182 -84.911395  \n",
      "17  34.377182 -84.911395  \n",
      "18  34.377088 -84.911870  \n",
      "19  34.375145 -84.910130  \n",
      "20  34.375145 -84.910130  \n",
      "21  34.375145 -84.910130  \n",
      "22  34.373140 -84.907750  \n",
      "23  34.365613 -84.900082  \n",
      "24  34.365613 -84.900082  \n",
      "25  34.365613 -84.900082  \n",
      "26  34.361695 -84.895935  \n",
      "27  34.355068 -84.886428  \n",
      "28  34.349388 -84.880490  \n",
      "29  34.342508 -84.873387  \n",
      "30  34.336770 -84.866675  \n",
      "31  34.329167 -84.857150  \n",
      "32  34.319278 -84.847053  \n",
      "33  34.277762 -84.815655  \n",
      "34  34.261470 -84.801132  \n",
      "35  34.261470 -84.801132  \n",
      "36  34.261470 -84.801132  \n",
      "37  34.250097 -84.785165  \n",
      "38  34.250097 -84.785165  \n",
      "39  34.250097 -84.785165  \n",
      "40  34.235508 -84.758778  \n",
      "41  34.235508 -84.758778  \n",
      "42  34.217737 -84.753010  \n",
      "43  34.217737 -84.753010  \n",
      "44  34.211465 -84.759635  \n",
      "45  34.203028 -84.761883  \n",
      "46  34.203028 -84.761883  \n",
      "47  34.193108 -84.765995  \n",
      "48  34.185338 -84.766002  \n",
      "49  34.176583 -84.759877  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import read_json\n",
    "from datetime import datetime\n",
    "\n",
    "def read_and_clean_json_file():\n",
    "    gps_df = read_json( 'valdosta1.gps', lines=True)\n",
    "\n",
    "    # GPS data stream is very rich - a lot of redundant info, including \n",
    "    # info on the satellites themselves.  We only want position (fix) related\n",
    "    # stuff.  TPV is Time, Position, Velocity\n",
    "    gps_clean = gps_df.loc[gps_df['class'] == 'TPV']\n",
    "\n",
    "    # Now keep only columns/fields we want\n",
    "    gps_clean = gps_clean.filter( items=['time', 'lat', 'lon', 'speed', 'alt', 'track', 'climb'])\n",
    "\n",
    "    # Deal with missing times\n",
    "    gps_clean = gps_clean.loc[(gps_clean['time'].notnull()) & gps_clean['climb'].notnull()]\n",
    "\n",
    "    # Convert string date to datetime internal format, add to dataframe as dt_tm\n",
    "    # Ref: https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior\n",
    "    # and: https://stackoverflow.com/questions/18942506/add-new-column-in-pandas-dataframe-python\n",
    "\n",
    "    # kludge to turn off the dreaded SettingWithCopyWarning.  Discussion is  in SO link above.\n",
    "    pd.options.mode.chained_assignment = None\n",
    "\n",
    "    # Compute a new column with a datetime format from the string date time column\n",
    "    # string dates and times look like this 2015-06-18T13:43:40.000Z\n",
    "    gps_clean['dt_tm'] = gps_clean['time'].map( lambda x: datetime.strptime(x, '%Y-%m-%dT%H:%M:%S.000Z'))\n",
    "\n",
    "    return gps_clean\n",
    "\n",
    "def read_and_clean_csv_file():\n",
    "\n",
    "    # Read the entire file\n",
    "    adsb_df = read_csv( 'valdosta1.adsb', names=['date_time', 'mode', 'flight_id', \n",
    "        'hex_id', 'altitude', 'lat_plane', 'lng_plane', 'in_view'])\n",
    "\n",
    "    # first subsetting expression -- only want updates, non-zero lat/long\n",
    "    adsb_clean = adsb_df.loc[(adsb_df['mode'] == 'Updating') & (adsb_df['lat_plane'] != 0 ) \n",
    "        & (adsb_df['lat_plane'].notnull())]\n",
    "\n",
    "    # Convert string date to datetime internal format, add to dataframe as dt_tm\n",
    "    # Ref: https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior\n",
    "    # and: https://stackoverflow.com/questions/18942506/add-new-column-in-pandas-dataframe-python\n",
    "\n",
    "    # kludge to turn off the dreaded SettingWithCopyWarning.  Discussion is  in SO link above.\n",
    "    pd.options.mode.chained_assignment = None\n",
    "\n",
    "    # Compute a new column with a datetime format from the string date time column\n",
    "    adsb_clean['dt_tm'] = adsb_clean['date_time'].map( lambda x: datetime.strptime(x, '%Y%m%d-%H%M%S'))\n",
    "\n",
    "    return adsb_clean\n",
    "\n",
    "# Based on: https://stackoverflow.com/questions/34880539/pandas-merging-based-on-a-timestamp-which-do-not-match-exactly\n",
    "# also: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge_asof.html\n",
    "def merge_planes_gps(planes, gps):\n",
    "    tol = pd.Timedelta( '1 minute')\n",
    "    all_df = pd.merge_asof(\n",
    "        left=planes,\n",
    "        right=gps,\n",
    "        direction='nearest',\n",
    "        on='dt_tm',\n",
    "        tolerance=tol)\n",
    "    return all_df\n",
    "\n",
    "def print_selected( result, n_rows):\n",
    "    print( result[['hex_id', 'date_time', 'lat_plane','lng_plane', 'time', 'lat', 'lon']].head(n_rows))\n",
    "\n",
    "def main():\n",
    "\n",
    "    adsb_clean = read_and_clean_csv_file( )\n",
    "    gps_clean = read_and_clean_json_file( )\n",
    "\n",
    "    result_df = merge_planes_gps( adsb_clean, gps_clean)\n",
    "    print( 'Selected rows')\n",
    "    print_selected( result_df, 50)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
